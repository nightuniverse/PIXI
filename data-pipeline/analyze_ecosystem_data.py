#!/usr/bin/env python3
"""
ìŠ¤íƒ€íŠ¸ì—… ìƒíƒœê³„ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Any
import os

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class EcosystemDataAnalyzer:
    def __init__(self, data_dir: str = "data"):
        self.data_dir = data_dir
        self.merged_data = None
        self.global_data = None
        self.korean_data = None
        
    def load_latest_data(self):
        """ìµœì‹  í†µí•© ë°ì´í„° ë¡œë“œ"""
        try:
            # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì°¾ê¸°
            files = [f for f in os.listdir(self.data_dir) if f.startswith('merged_ecosystem_data')]
            if not files:
                print("í†µí•© ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            latest_file = max(files, key=lambda x: os.path.getctime(os.path.join(self.data_dir, x)))
            filepath = os.path.join(self.data_dir, latest_file)
            
            with open(filepath, 'r', encoding='utf-8') as f:
                self.merged_data = json.load(f)
            
            self.global_data = self.merged_data.get('global_ecosystem', {})
            self.korean_data = self.merged_data.get('korean_ecosystem', {})
            
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {latest_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_ecosystem_composition(self):
        """ìƒíƒœê³„ êµ¬ì„± ë¶„ì„"""
        print("\nğŸ” ìƒíƒœê³„ êµ¬ì„± ë¶„ì„")
        print("=" * 50)
        
        if not self.merged_data:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ì „ì²´ í†µê³„
        merged_stats = self.merged_data.get('merged_statistics', {})
        
        print(f"ğŸŒ ì „ì²´ ìƒíƒœê³„:")
        print(f"   - ê³ ìœ  ìŠ¤íƒ€íŠ¸ì—…: {merged_stats.get('total_unique_startups', 0):,}ê°œ")
        print(f"   - ê³ ìœ  íˆ¬ìì: {merged_stats.get('total_unique_investors', 0):,}ê°œ")
        print(f"   - ê³ ìœ  ì•¡ì…€ëŸ¬ë ˆì´í„°: {merged_stats.get('total_unique_accelerators', 0):,}ê°œ")
        print(f"   - ê³ ìœ  ì½”ì›Œí‚¹ ìŠ¤í˜ì´ìŠ¤: {merged_stats.get('total_unique_coworking_spaces', 0):,}ê°œ")
        print(f"   - ê³ ìœ  ì´ë²¤íŠ¸: {merged_stats.get('total_unique_events', 0):,}ê°œ")
        
        # í•œêµ­ ìƒíƒœê³„ í†µê³„
        korean_stats = self.korean_data.get('statistics', {})
        print(f"\nğŸ‡°ğŸ‡· í•œêµ­ ìƒíƒœê³„:")
        print(f"   - ìŠ¤íƒ€íŠ¸ì—…: {korean_stats.get('total_startups', 0):,}ê°œ")
        print(f"   - íˆ¬ìì: {korean_stats.get('total_investors', 0):,}ê°œ")
        print(f"   - ì•¡ì…€ëŸ¬ë ˆì´í„°: {korean_stats.get('total_accelerators', 0):,}ê°œ")
        print(f"   - ì½”ì›Œí‚¹ ìŠ¤í˜ì´ìŠ¤: {korean_stats.get('total_coworking_spaces', 0):,}ê°œ")
        print(f"   - ë‰´ìŠ¤: {korean_stats.get('total_news', 0):,}ê°œ")
    
    def analyze_startup_categories(self):
        """ìŠ¤íƒ€íŠ¸ì—… ì¹´í…Œê³ ë¦¬ ë¶„ì„"""
        print("\nğŸ“Š ìŠ¤íƒ€íŠ¸ì—… ì¹´í…Œê³ ë¦¬ ë¶„ì„")
        print("=" * 50)
        
        if not self.merged_data:
            return
        
        # ëª¨ë“  ìŠ¤íƒ€íŠ¸ì—… ë°ì´í„° ìˆ˜ì§‘
        all_startups = []
        
        # ê¸€ë¡œë²Œ ìŠ¤íƒ€íŠ¸ì—…
        global_startups = self.global_data.get('startups', [])
        for startup in global_startups:
            startup['ecosystem'] = 'Global'
            all_startups.append(startup)
        
        # í•œêµ­ ìŠ¤íƒ€íŠ¸ì—…
        korean_startups = self.korean_data.get('startups', [])
        for startup in korean_startups:
            startup['ecosystem'] = 'Korean'
            all_startups.append(startup)
        
        if not all_startups:
            print("ë¶„ì„í•  ìŠ¤íƒ€íŠ¸ì—… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        categories = {}
        for startup in all_startups:
            category = startup.get('category', 'Unknown')
            if category not in categories:
                categories[category] = {'count': 0, 'startups': []}
            categories[category]['count'] += 1
            categories[category]['startups'].append(startup['name'])
        
        # ê²°ê³¼ ì¶œë ¥
        for category, data in categories.items():
            print(f"\nğŸ“ {category}: {data['count']}ê°œ")
            for startup_name in data['startups'][:5]:  # ìƒìœ„ 5ê°œë§Œ
                print(f"   - {startup_name}")
            if len(data['startups']) > 5:
                print(f"   ... ë° {len(data['startups']) - 5}ê°œ ë”")
    
    def analyze_geographic_distribution(self):
        """ì§€ë¦¬ì  ë¶„í¬ ë¶„ì„"""
        print("\nğŸŒ ì§€ë¦¬ì  ë¶„í¬ ë¶„ì„")
        print("=" * 50)
        
        if not self.merged_data:
            return
        
        # ëª¨ë“  ì—”í‹°í‹°ì˜ ìœ„ì¹˜ ì •ë³´ ìˆ˜ì§‘
        locations = {}
        
        # ê¸€ë¡œë²Œ ë°ì´í„°
        for entity_type in ['startups', 'investors', 'accelerators', 'coworking_spaces']:
            entities = self.global_data.get(entity_type, [])
            for entity in entities:
                location = entity.get('location', 'Unknown')
                if location not in locations:
                    locations[location] = {'count': 0, 'types': set()}
                locations[location]['count'] += 1
                locations[location]['types'].add(entity_type)
        
        # í•œêµ­ ë°ì´í„°
        for entity_type in ['startups', 'investors', 'accelerators', 'coworking_spaces']:
            entities = self.korean_data.get(entity_type, [])
            for entity in entities:
                location = entity.get('location', 'Unknown')
                if location not in locations:
                    locations[location] = {'count': 0, 'types': set()}
                locations[location]['count'] += 1
                locations[location]['types'].add(entity_type)
        
        # ê²°ê³¼ ì¶œë ¥
        sorted_locations = sorted(locations.items(), key=lambda x: x[1]['count'], reverse=True)
        
        for location, data in sorted_locations[:10]:  # ìƒìœ„ 10ê°œ
            types_str = ', '.join(sorted(data['types']))
            print(f"ğŸ“ {location}: {data['count']}ê°œ ({types_str})")
    
    def create_visualizations(self):
        """ë°ì´í„° ì‹œê°í™” ìƒì„±"""
        print("\nğŸ“ˆ ë°ì´í„° ì‹œê°í™” ìƒì„± ì¤‘...")
        
        if not self.merged_data:
            print("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 1. ìƒíƒœê³„ êµ¬ì„± íŒŒì´ ì°¨íŠ¸
        self._create_ecosystem_pie_chart()
        
        # 2. í•œêµ­ vs ê¸€ë¡œë²Œ ë¹„êµ ì°¨íŠ¸
        self._create_comparison_chart()
        
        # 3. ì‹œê°„ë³„ í¬ë¡¤ë§ ê²°ê³¼
        self._create_timeline_chart()
        
        print("âœ… ì‹œê°í™” ì™„ë£Œ! charts/ ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    def _create_ecosystem_pie_chart(self):
        """ìƒíƒœê³„ êµ¬ì„± íŒŒì´ ì°¨íŠ¸"""
        try:
            # í•œêµ­ ìƒíƒœê³„ ë°ì´í„°
            korean_stats = self.korean_data.get('statistics', {})
            
            labels = ['ìŠ¤íƒ€íŠ¸ì—…', 'íˆ¬ìì', 'ì•¡ì…€ëŸ¬ë ˆì´í„°', 'ì½”ì›Œí‚¹ ìŠ¤í˜ì´ìŠ¤', 'ë‰´ìŠ¤']
            sizes = [
                korean_stats.get('total_startups', 0),
                korean_stats.get('total_investors', 0),
                korean_stats.get('total_accelerators', 0),
                korean_stats.get('total_coworking_spaces', 0),
                korean_stats.get('total_news', 0)
            ]
            
            # 0ì´ ì•„ë‹Œ ê°’ë§Œ í•„í„°ë§
            filtered_labels = [label for label, size in zip(labels, sizes) if size > 0]
            filtered_sizes = [size for size in sizes if size > 0]
            
            if not filtered_sizes:
                return
            
            plt.figure(figsize=(10, 8))
            plt.pie(filtered_sizes, labels=filtered_labels, autopct='%1.1f%%', startangle=90)
            plt.title('ğŸ‡°ğŸ‡· í•œêµ­ ìŠ¤íƒ€íŠ¸ì—… ìƒíƒœê³„ êµ¬ì„±', fontsize=16, pad=20)
            plt.axis('equal')
            
            # charts ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs('charts', exist_ok=True)
            plt.savefig('charts/korean_ecosystem_composition.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            print(f"íŒŒì´ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _create_comparison_chart(self):
        """í•œêµ­ vs ê¸€ë¡œë²Œ ë¹„êµ ì°¨íŠ¸"""
        try:
            # ë°ì´í„° ì¤€ë¹„
            categories = ['ìŠ¤íƒ€íŠ¸ì—…', 'íˆ¬ìì', 'ì•¡ì…€ëŸ¬ë ˆì´í„°', 'ì½”ì›Œí‚¹ ìŠ¤í˜ì´ìŠ¤']
            
            korean_counts = [
                self.korean_data.get('statistics', {}).get('total_startups', 0),
                self.korean_data.get('statistics', {}).get('total_investors', 0),
                self.korean_data.get('statistics', {}).get('total_accelerators', 0),
                self.korean_data.get('statistics', {}).get('total_coworking_spaces', 0)
            ]
            
            global_counts = [
                self.global_data.get('statistics', {}).get('total_startups', 0),
                self.global_data.get('statistics', {}).get('total_investors', 0),
                self.global_data.get('statistics', {}).get('total_accelerators', 0),
                self.global_data.get('statistics', {}).get('total_coworking_spaces', 0)
            ]
            
            # ì°¨íŠ¸ ìƒì„±
            x = range(len(categories))
            width = 0.35
            
            plt.figure(figsize=(12, 8))
            plt.bar([i - width/2 for i in x], korean_counts, width, label='ğŸ‡°ğŸ‡· í•œêµ­', color='skyblue')
            plt.bar([i + width/2 for i in x], global_counts, width, label='ğŸŒ ê¸€ë¡œë²Œ', color='lightcoral')
            
            plt.xlabel('ì—”í‹°í‹° ìœ í˜•', fontsize=12)
            plt.ylabel('ê°œìˆ˜', fontsize=12)
            plt.title('í•œêµ­ vs ê¸€ë¡œë²Œ ìƒíƒœê³„ ë¹„êµ', fontsize=16, pad=20)
            plt.xticks(x, categories)
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            # ê°’ í‘œì‹œ
            for i, (kr, gl) in enumerate(zip(korean_counts, global_counts)):
                plt.text(i - width/2, kr + 0.1, str(kr), ha='center', va='bottom')
                plt.text(i + width/2, gl + 0.1, str(gl), ha='center', va='bottom')
            
            plt.tight_layout()
            plt.savefig('charts/ecosystem_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            print(f"ë¹„êµ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _create_timeline_chart(self):
        """ì‹œê°„ë³„ í¬ë¡¤ë§ ê²°ê³¼ ì°¨íŠ¸"""
        try:
            # í¬ë¡¤ë§ ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘
            timeline_data = []
            
            # ê¸€ë¡œë²Œ ë°ì´í„°
            global_time = self.global_data.get('crawled_at')
            if global_time:
                timeline_data.append(('ê¸€ë¡œë²Œ', global_time, 0))
            
            # í•œêµ­ ë°ì´í„°
            korean_time = self.korean_data.get('crawled_at')
            if korean_time:
                korean_stats = self.korean_data.get('statistics', {})
                total_entities = korean_stats.get('total_entities', 0)
                timeline_data.append(('í•œêµ­', korean_time, total_entities))
            
            if not timeline_data:
                return
            
            # ì‹œê°„ íŒŒì‹±
            times = []
            labels = []
            counts = []
            
            for label, time_str, count in timeline_data:
                try:
                    dt = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
                    times.append(dt)
                    labels.append(label)
                    counts.append(count)
                except:
                    continue
            
            if not times:
                return
            
            # ì°¨íŠ¸ ìƒì„±
            plt.figure(figsize=(10, 6))
            plt.plot(times, counts, marker='o', linewidth=2, markersize=8)
            
            for i, (time, count, label) in enumerate(zip(times, counts, labels)):
                plt.annotate(f'{label}\n{count}ê°œ', 
                           (time, count), 
                           textcoords="offset points", 
                           xytext=(0,10), 
                           ha='center')
            
            plt.title('ğŸ“Š ì‹œê°„ë³„ í¬ë¡¤ë§ ê²°ê³¼', fontsize=16, pad=20)
            plt.xlabel('ì‹œê°„', fontsize=12)
            plt.ylabel('ìˆ˜ì§‘ëœ ì—”í‹°í‹° ìˆ˜', fontsize=12)
            plt.grid(True, alpha=0.3)
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            plt.savefig('charts/crawling_timeline.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            print(f"íƒ€ì„ë¼ì¸ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def generate_insights_report(self):
        """ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\nğŸ’¡ ìƒíƒœê³„ ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸")
        print("=" * 50)
        
        if not self.merged_data:
            print("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # í•œêµ­ ìƒíƒœê³„ ë¶„ì„
        korean_stats = self.korean_data.get('statistics', {})
        korean_startups = self.korean_data.get('startups', [])
        korean_accelerators = self.korean_data.get('accelerators', [])
        korean_coworking = self.korean_data.get('coworking_spaces', [])
        
        print("ğŸ‡°ğŸ‡· í•œêµ­ ìŠ¤íƒ€íŠ¸ì—… ìƒíƒœê³„ íŠ¹ì§•:")
        
        # ì•¡ì…€ëŸ¬ë ˆì´í„° ë¶„ì„
        if korean_accelerators:
            print(f"   â€¢ {len(korean_accelerators)}ê°œì˜ ì£¼ìš” ì•¡ì…€ëŸ¬ë ˆì´í„°ê°€ í™œë™ ì¤‘")
            focus_areas = set()
            for acc in korean_accelerators:
                focus = acc.get('focus', '')
                if focus:
                    focus_areas.update([area.strip() for area in focus.split(',')])
            
            if focus_areas:
                print(f"   â€¢ ì£¼ìš” íˆ¬ì ë¶„ì•¼: {', '.join(sorted(focus_areas))}")
        
        # ì½”ì›Œí‚¹ ìŠ¤í˜ì´ìŠ¤ ë¶„ì„
        if korean_coworking:
            print(f"   â€¢ {len(korean_coworking)}ê°œì˜ ì£¼ìš” ì½”ì›Œí‚¹ ìŠ¤í˜ì´ìŠ¤ ìš´ì˜ ì¤‘")
            locations = set()
            for space in korean_coworking:
                location = space.get('location', '')
                if location:
                    locations.add(location)
            
            if locations:
                print(f"   â€¢ ì£¼ìš” ìš´ì˜ ì§€ì—­: {', '.join(sorted(locations))}")
        
        # ìŠ¤íƒ€íŠ¸ì—… ë¶„ì„
        if korean_startups:
            print(f"   â€¢ {len(korean_startups)}ê°œì˜ ìŠ¤íƒ€íŠ¸ì—… ì •ë³´ ìˆ˜ì§‘ë¨")
            sources = set()
            for startup in korean_startups:
                source = startup.get('source', '')
                if source:
                    sources.add(source)
            
            if sources:
                print(f"   â€¢ ì •ë³´ ì†ŒìŠ¤: {', '.join(sorted(sources))}")
        
        # ê¸€ë¡œë²Œ ìƒíƒœê³„ ë¶„ì„
        global_stats = self.global_data.get('statistics', {})
        global_entities = global_stats.get('total_entities', 0)
        
        print(f"\nğŸŒ ê¸€ë¡œë²Œ ìƒíƒœê³„ í˜„í™©:")
        print(f"   â€¢ ìˆ˜ì§‘ëœ ì—”í‹°í‹°: {global_entities}ê°œ")
        
        if global_entities == 0:
            print("   â€¢ í˜„ì¬ ê¸€ë¡œë²Œ ë°ì´í„° ìˆ˜ì§‘ì´ ì œí•œì ì„")
            print("   â€¢ ì›¹ì‚¬ì´íŠ¸ ì°¨ë‹¨ ë° ì ‘ê·¼ ì œí•œìœ¼ë¡œ ì¸í•œ ì œì•½")
        
        # ê°œì„  ì œì•ˆ
        print(f"\nğŸš€ ê°œì„  ì œì•ˆ:")
        print("   â€¢ í•œêµ­ ìƒíƒœê³„ ë°ì´í„°ëŠ” ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ì§‘ë˜ê³  ìˆìŒ")
        print("   â€¢ ê¸€ë¡œë²Œ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•œ ëŒ€ì•ˆ ë°©ë²• ëª¨ìƒ‰ í•„ìš”")
        print("   â€¢ API ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘ ë° í˜‘ë ¥ íŒŒíŠ¸ë„ˆì‹­ ê³ ë ¤")
        print("   â€¢ ì •ê¸°ì ì¸ ë°ì´í„° ì—…ë°ì´íŠ¸ ë° í’ˆì§ˆ ê´€ë¦¬ í•„ìš”")
    
    def save_analysis_report(self):
        """ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # ë¦¬í¬íŠ¸ ë‚´ìš© ìƒì„±
            report = {
                'analysis_timestamp': datetime.now().isoformat(),
                'data_source': 'merged_ecosystem_data',
                'summary': {
                    'total_unique_startups': self.merged_data.get('merged_statistics', {}).get('total_unique_startups', 0),
                    'total_unique_investors': self.merged_data.get('merged_statistics', {}).get('total_unique_investors', 0),
                    'total_unique_accelerators': self.merged_data.get('merged_statistics', {}).get('total_unique_accelerators', 0),
                    'total_unique_coworking_spaces': self.merged_data.get('merged_statistics', {}).get('total_unique_coworking_spaces', 0),
                    'total_unique_events': self.merged_data.get('merged_statistics', {}).get('total_unique_events', 0)
                },
                'korean_ecosystem': self.korean_data.get('statistics', {}),
                'global_ecosystem': self.global_data.get('statistics', {}),
                'analysis_notes': [
                    "í•œêµ­ ìƒíƒœê³„ ë°ì´í„°ëŠ” ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ì§‘ë¨",
                    "ê¸€ë¡œë²Œ ë°ì´í„° ìˆ˜ì§‘ì€ ì›¹ì‚¬ì´íŠ¸ ì°¨ë‹¨ìœ¼ë¡œ ì œí•œì ",
                    "ì•¡ì…€ëŸ¬ë ˆì´í„°ì™€ ì½”ì›Œí‚¹ ìŠ¤í˜ì´ìŠ¤ ì •ë³´ê°€ í’ë¶€í•¨",
                    "ì •ê¸°ì ì¸ ë°ì´í„° ì—…ë°ì´íŠ¸ í•„ìš”"
                ]
            }
            
            # íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"analysis_report_{timestamp}.json"
            filepath = os.path.join(self.data_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {filename}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ” ìŠ¤íƒ€íŠ¸ì—… ìƒíƒœê³„ ë°ì´í„° ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = EcosystemDataAnalyzer()
    
    # ë°ì´í„° ë¡œë“œ
    if not analyzer.load_latest_data():
        print("ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í¬ë¡¤ë§ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # 1. ìƒíƒœê³„ êµ¬ì„± ë¶„ì„
    analyzer.analyze_ecosystem_composition()
    
    # 2. ìŠ¤íƒ€íŠ¸ì—… ì¹´í…Œê³ ë¦¬ ë¶„ì„
    analyzer.analyze_startup_categories()
    
    # 3. ì§€ë¦¬ì  ë¶„í¬ ë¶„ì„
    analyzer.analyze_geographic_distribution()
    
    # 4. ì‹œê°í™” ìƒì„±
    analyzer.create_visualizations()
    
    # 5. ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
    analyzer.generate_insights_report()
    
    # 6. ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥
    analyzer.save_analysis_report()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ìƒíƒœê³„ ë°ì´í„° ë¶„ì„ ì™„ë£Œ!")
    print("ğŸ“Š ì°¨íŠ¸ íŒŒì¼: charts/ ë””ë ‰í† ë¦¬")
    print("ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸: data/ ë””ë ‰í† ë¦¬")

if __name__ == "__main__":
    main()
